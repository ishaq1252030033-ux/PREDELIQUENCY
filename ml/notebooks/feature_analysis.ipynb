{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis for Pre-Delinquency Intervention Engine\n",
    "\n",
    "This notebook loads engineered features and performs exploratory data analysis and feature importance analysis for pre-delinquency risk prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "plt.style.use('seaborn-v0_8-muted')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'ml' / 'data' / 'processed'\n",
    "LABELS_PATH = PROJECT_ROOT / 'ml' / 'data' / 'labels.csv'\n",
    "REPORTS_DIR = PROJECT_ROOT / 'ml' / 'reports'\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "features_path = DATA_DIR / 'features.csv'\n",
    "print(f'Loading features from: {features_path}')\n",
    "features = pd.read_csv(features_path)\n",
    "\n",
    "labels = pd.read_csv(LABELS_PATH)\n",
    "data = features.merge(labels, on='customer_id', how='inner')\n",
    "print(f'Data shape: {data.shape}')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info and summary statistics\n",
    "display(data.describe().T)\n",
    "data['default'].value_counts(normalize=True).rename('default_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots for each numerical feature\n",
    "num_features = [col for col in data.columns if col not in ['customer_id', 'default']]\n",
    "\n",
    "for col in num_features:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    sns.histplot(data[col], kde=True, ax=ax)\n",
    "    ax.set_title(f'Distribution of {col}')\n",
    "    ax.set_xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    out_path = REPORTS_DIR / f'dist_{col}.png'\n",
    "    fig.savefig(out_path, dpi=120)\n",
    "    plt.close(fig)\n",
    "\n",
    "len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap between features\n",
    "corr = data[num_features].corr()\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, ax=ax)\n",
    "ax.set_title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "out_path = REPORTS_DIR / 'correlation_heatmap.png'\n",
    "fig.savefig(out_path, dpi=140)\n",
    "plt.close(fig)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature vs target relationship (boxplots)\n",
    "for col in num_features:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    sns.boxplot(x='default', y=col, data=data, ax=ax)\n",
    "    ax.set_title(f'{col} by Default Status')\n",
    "    plt.tight_layout()\n",
    "    out_path = REPORTS_DIR / f'box_{col}_vs_default.png'\n",
    "    fig.savefig(out_path, dpi=120)\n",
    "    plt.close(fig)\n",
    "\n",
    "len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for feature importance\n",
    "X = data[num_features].copy()\n",
    "y = data['default'].astype(int)\n",
    "\n",
    "# Handle any NaNs (should be rare after our pipeline)\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# For chi-square, features must be non-negative; scale to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/val split for RandomForest\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train_rf = X_train.copy()\n",
    "y_train_rf = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual information\n",
    "mi_scores = mutual_info_classif(X_scaled, y, random_state=42)\n",
    "mi_series = pd.Series(mi_scores, index=num_features, name='mutual_information').sort_values(ascending=False)\n",
    "mi_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square\n",
    "chi2_scores, chi2_p = chi2(X_scaled, y)\n",
    "chi2_series = pd.Series(chi2_scores, index=num_features, name='chi2').sort_values(ascending=False)\n",
    "chi2_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest feature importance\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf.fit(X_train_rf, y_train_rf)\n",
    "rf_importances = pd.Series(rf.feature_importances_, index=num_features, name='rf_importance').sort_values(ascending=False)\n",
    "rf_importances.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine importance scores into a single DataFrame\n",
    "importance_df = pd.concat([mi_series, chi2_series, rf_importances], axis=1)\n",
    "importance_df.sort_values('rf_importance', ascending=False, inplace=True)\n",
    "importance_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 10 most important features by Random Forest importance\n",
    "top_n = 10\n",
    "top_rf = importance_df.head(top_n)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.barplot(x=top_rf['rf_importance'], y=top_rf.index, ax=ax, orient='h')\n",
    "ax.set_title('Top 10 Features by Random Forest Importance')\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "out_path = REPORTS_DIR / 'top10_rf_importance.png'\n",
    "fig.savefig(out_path, dpi=140)\n",
    "plt.close(fig)\n",
    "\n",
    "top_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of each feature with default\n",
    "corr_with_default = data[num_features + ['default']].corr()['default'].drop('default').sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "corr_with_default.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 10 strongest correlations with default\n",
    "top_corr = corr_with_default.head(10)\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.barplot(x=top_corr.values, y=top_corr.index, ax=ax, orient='h')\n",
    "ax.set_title('Top 10 Feature Correlations with Default')\n",
    "ax.set_xlabel('Correlation with default')\n",
    "ax.set_ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "out_path = REPORTS_DIR / 'top10_corr_with_default.png'\n",
    "fig.savefig(out_path, dpi=140)\n",
    "plt.close(fig)\n",
    "\n",
    "top_corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
